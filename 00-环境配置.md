# Python爬虫环境配置

## MongoDB

+ 安装包

  + **官网下载地址：https://www.mongodb.com/download-center#community 下载   安装包。**

+ （坑）安装时不要勾选

  ![keng](https://img-blog.csdn.net/20180628162152214?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FydGZ1bF9Eb2RnZXI=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

+ 创建data文件夹，继续创建db文件夹
+ 输入如下命令启动mongodb服务

```powershell
mongod --dbpath xxx\data\db
```

+ **在浏览器输入http://localhost:27017 （27017是mongodb的端口号）查看**

```
It looks like you are trying to access MongoDB over HTTP on the native driver port.
```

+ 将MongoDB设置为 系统服务

```powershell
.\mongod.exe --bind_ip 0.0.0.0 --logpath "C:\Program Files\MongoDB\Server\3.
6\data\logs\mongo.log" --logappend --dbpath "C:\Program Files\MongoDB\Server\3.6\data\db" --port 27017 --serviceName "Mo
ngoDB" --serviceDisplayName "MongoDB" --install
```

## Robomongo

## 爬虫常用库的安装

### requests

```powershell
pip3 install requests -i https://pypi.mirrors.ustc.edu.cn/simple/
```

### selenium

爬虫时会遇到js渲染的网页。这时候用requests请求的时候无法正常获取请求内容。selenium用于驱动浏览器执行js渲染，得到渲染后的页面。主要用于自动化测试。

```pow
 pip3 install selenium -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

```python
from selenium import webdriver
driver = webdriver.Chrome()
# 'chromedriver' executable needs to be in PATH.
```

### chromedriver

下载地址：<https://chromedriver.storage.googleapis.com/index.html> | 科学上网

解压到PATH路径即可

```python
from selenium import webdriver
driver = webdriver.Chrome()
driver.get("http://59.67.225.73")
print(driver.page_source)
```

运行后会自动打开一个带界面的Chrome

### PhantomJS

下载地址： <http://phantomjs.org/download.html>

API : http://phantomjs.org/api/command-line.html

解压后，将bin目录添加到环境变量

```python
from selenium import webdriver
driver = webdriver.PhantomJS()
driver.get("http://59.67.243.175")
driver.page_source
```

### lxml

提供了xpath的解析方式，对网页进行解析

```powershell
pip3 install lxml -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

### beautifulsoap

依赖于lxml

```powershell
 pip3 install beautifulsoup4 -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

```python
from bs4 import BeautifulSoup
soup = BeautifulSoup("<html></html", "lxml")
```

### pyquery

语法跟jQuery类似

```po
pip3 install beautifulsoup4 -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

API文档

<https://pythonhosted.org/pyquery/>

### pymysql

```powershell
pip3 install pymysql -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

```python
import pymysql
conn = pymysql.connect(host="localhost", user="root", password="zyh19970720", port=3306, db="ncepu")
cursor = conn.cursor()
cursor.execute("select * from gm_bj")
print(cursor.fetchall()) # 元组嵌套
```



### pymongo

```powershell
pip3 install pymongo -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

```python
import pymongo
client = pymongo.MongoClient("localhost")
db = client['newtestdb']
db['table'].insert_one({"name":"Bob"})
db['table'].find_one({"name":"Bob"})
# DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.
#   db['table'].insert({"name":"Bob"})
```

### redis

分布式爬虫用，维护一个爬取队列，运行效率较高

```powershell
 pip3 install redis -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

```python
import redis
r = redis.Redis("localhost", 6379)
r.set('name','Bob')
print(r.get('name')) # b'Bob'
```

### flask

设置web服务器，代理接口

```shell
pip3 install flask -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

入门文档

快速入门： <http://www.pythondoc.com/flask-sqlalchemy/quickstart.html>

官方文档：<http://flask.pocoo.org/docs/1.0/>

### Django

提供了完整的后台管理，模板引擎，路由等等

在后期分布式爬虫 维护的时候需要管理主机信息

```powershell
pip3 install django -i  https://pypi.mirrors.ustc.edu.cn/simple/
```

### jupyter

记事本，运行在网页端，可以写一些代码，进行调试运行，支持markdown

安装后可以直接在命令行使用

```powershell
pip3 install jupyter -i  https://pypi.mirrors.ustc.edu.cn/simple/

jupyter notebook
```

占用8888端口